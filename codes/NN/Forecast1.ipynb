{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "Using TensorFlow backend.\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# univariate multi-step encoder-decoder cnn-lstm\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib import pyplot\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, LSTM, RepeatVector, TimeDistributed, Dropout, Embedding\n",
    "\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.regularizers import l1_l2, l1, l2\n",
    "from keras.callbacks import EarlyStopping"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def split_dataset(data,split=0.8):\n",
    "    Nrow, Ncol = data.shape\n",
    "    splitRows = math.ceil(Nrow * split)\n",
    "    \n",
    "    train,test = data.loc[0:splitRows], data.loc[splitRows+1:Nrow]\n",
    "    print(train.shape)\n",
    "    print(test.shape)\n",
    "    \n",
    "    return train, test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# evaluate one or more weekly forecasts against expected values\n",
    "def evaluate_forecasts(actual, predicted):\n",
    "\tscores = list()\n",
    "\t# calculate an RMSE score for each day\n",
    "\tfor i in range(actual.shape[1]):\n",
    "\t\t# calculate mse\n",
    "\t\tmse = mean_squared_error(actual[:, i], predicted[:, i])\n",
    "\t\t# calculate rmse\n",
    "\t\trmse = math.sqrt(mse)\n",
    "\t\t# store\n",
    "\t\tscores.append(rmse)\n",
    "\t# calculate overall RMSE\n",
    "\ts = 0\n",
    "\tfor row in range(actual.shape[0]):\n",
    "\t\tfor col in range(actual.shape[1]):\n",
    "\t\t\ts += (actual[row, col] - predicted[row, col])**2\n",
    "\tscore = math.sqrt(s / (actual.shape[0] * actual.shape[1]))\n",
    "\treturn score, scores"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# summarize scores\n",
    "def summarize_scores(name, score, scores):\n",
    "\ts_scores = ', '.join(['%.1f' % s for s in scores])\n",
    "\tprint('%s: [%.3f] %s' % (name, score, s_scores))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# convert history into inputs and outputs\n",
    "def to_supervised(train, n_input, n_out=200):\n",
    "    # flatten data\n",
    "    data = np.array(train)\n",
    "    data = data.reshape((data.shape[0]*data.shape[1], data.shape[2]))\n",
    "    X, y = list(), list()\n",
    "    in_start = 0\n",
    "    # step over the entire history one time step at a time\n",
    "    for _ in range(len(data)):\n",
    "    # define the end of the input sequence\n",
    "        in_end = in_start + n_input\n",
    "        out_end = in_end + n_out\n",
    "        # ensure we have enough data for this instance\n",
    "        if out_end <= len(data):\n",
    "            x_input = data[in_start:in_end, -3]\n",
    "            x_input = x_input.reshape((len(x_input), 1))\n",
    "            X.append(x_input)\n",
    "            y.append(data[in_end:out_end, -3])\n",
    "            # move along one time step\n",
    "            in_start += 1\n",
    "    return np.array(X), np.array(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def build_model_2(train, n_input):\n",
    "    # prepare data\n",
    "    train_x, train_y = to_supervised(train, n_input)\n",
    "    # define parameters\n",
    "    verbose, epochs, batch_size = 0, 50, 200\n",
    "    n_timesteps, n_features, n_outputs = train_x.shape[1], train_x.shape[2], train_y.shape[1]\n",
    "    # reshape output into [samples, timesteps, features]\n",
    "    train_y = train_y.reshape((train_y.shape[0], train_y.shape[1], 1)) #Features es 3?\n",
    "    \n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu',\n",
    "                                 kernel_regularizer=l2(0.001), bias_regularizer=l2(0.001),\n",
    "                                 input_shape=(None, n_timesteps, n_features))))\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu',\n",
    "                                 kernel_regularizer=l2(0.001), bias_regularizer=l2(0.001))))\n",
    "    model.add(TimeDistributed(Dropout(0.5)))\n",
    "    model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(RepeatVector(n_outputs))\n",
    "    #model.add(CuDNNLSTM(32, kernel_regularizer=l2(0.0001), bias_regularizer=l2(0.0001),\n",
    "    #                 recurrent_regularizer=l2(0.0001), activity_regularizer=l2(0.0001),\n",
    "    #               return_sequences = False))\n",
    "    model.add(LSTM(200, activation='relu', return_sequences=True))\n",
    "    #model.add(CuDNNLSTM(50, kernel_regularizer=l2(0.001), bias_regularizer=l2(0.001),\n",
    "    #                    recurrent_regularizer=l2(0.001), activity_regularizer=l2(0.001)))\n",
    "    #model.add(Dropout(0.5)) #DESCOMENTADO respecto al email\n",
    "    model.add(Dense(32, activation='relu',kernel_regularizer=l2(0.0001), bias_regularizer=l2(0.0001)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='nadam')#, metrics=['accuracy'])\n",
    "    \n",
    "    # fit network\n",
    "    model.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, verbose=1)\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "\n",
    "# train the model\n",
    "def build_model(train, n_input):\n",
    "    # prepare data\n",
    "    train_x, train_y = to_supervised(train, n_input)\n",
    "    #train_x shape(1093, 14, 1) <- inputs\n",
    "    #train_y shape(1093, 7)\n",
    "    # define parameters\n",
    "    verbose, epochs, batch_size = 1, 2, 200\n",
    "    n_timesteps, n_features, n_outputs = train_x.shape[1], train_x.shape[2], train_y.shape[1]\n",
    "    # reshape output into [samples, timesteps, features]\n",
    "    train_y = train_y.reshape((train_y.shape[0], train_y.shape[1], 1))\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_timesteps,n_features)))\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(RepeatVector(n_outputs))\n",
    "    \n",
    "    model.add(LSTM(200, activation='relu', return_sequences=True))\n",
    "    \n",
    "    model.add(TimeDistributed(Dense(100, activation='relu')))\n",
    "    #model.add(TimeDistributed(Dropout(0.2)))\n",
    "    model.add(TimeDistributed(Dense(1)))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='nadam')\n",
    "    # fit network\n",
    "    model.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    return model\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "  # make a forecast\n",
    "def forecast(model, history, n_input):\n",
    "    data = np.array(history)\n",
    "    data = data.reshape((data.shape[0]*data.shape[1], data.shape[2]))\n",
    "    # retrieve last observations for input data\n",
    "    input_x = data[-n_input:, -3]\n",
    "    # reshape into [1, n_input, 1]\n",
    "    input_x = input_x.reshape((1, len(input_x), 1))\n",
    "    # forecast the next week\n",
    "    yhat = model.predict(input_x, verbose=0)\n",
    "    # we only want the vector forecast\n",
    "    yhat = yhat[0]\n",
    "    print(yhat)\n",
    "    return yhat"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# evaluate a single model\n",
    "def evaluate_model(train, test, n_input):\n",
    "\t# fit model\n",
    "\tmodel = build_model(train, n_input)\n",
    "\t# history is a list of weekly data\n",
    "\thistory = [x for x in train]\n",
    "\t# walk-forward validation over each week\n",
    "\tpredictions = list()\n",
    "\tfor i in range(len(test)):\n",
    "\t\t# predict the week\n",
    "\t\tyhat_sequence = forecast(model, history, n_input)\n",
    "\t\t# store the predictions\n",
    "\t\tpredictions.append(yhat_sequence)\n",
    "\t\t# get real observation and add to history for predicting the next week\n",
    "\t\thistory.append(test[i, :])\n",
    "\t# evaluate predictions days for each week\n",
    "\tpredictions = np.array(predictions)\n",
    "\tscore, scores = evaluate_forecasts(test[:, :, 0], predictions)\n",
    "\treturn score, scores"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Index(['No.', 'Time', '∆t', 'Protocol', 'pkt_len', 'ip_len', 'tcp_hea_len',\n",
      "       'tcp_flag_ack', 'tcp_flag_cwr', 'tcp_flag_ecn', 'tcp_flag_urg',\n",
      "       'tcp_flag_psh', 'tcp_flag_rst', 'tcp_flag_syn', 'tcp_flag_fin',\n",
      "       'tcp_win_si2', 'delay', 'capture', 'prebuffering', 'stalling_event'],\n",
      "      dtype='object')\n",
      "Index(['∆t', 'pkt_len', 'ip_len', 'tcp_hea_len', 'tcp_flag_ack',\n",
      "       'tcp_flag_cwr', 'tcp_flag_ecn', 'tcp_flag_urg', 'tcp_flag_psh',\n",
      "       'tcp_flag_rst', 'tcp_flag_syn', 'tcp_flag_fin', 'tcp_win_si2',\n",
      "       'stalling_event'],\n",
      "      dtype='object')\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "df = pd.read_csv('../../output/df_general.csv')\n",
    "print(df.columns)\n",
    "\n",
    "df = df.drop(columns=['No.','Protocol','prebuffering','Time','capture','delay'])\n",
    "#df = df.astype(dtype= {\"pkt_length\":np.uint16, 'ip_len':np.uint16, 'tcp_win_si2':np.uint16,\n",
    "#                       'stalling_event':np.uint8, 'measure':np.uint8, 'capture':np.uint8})\n",
    "print(df.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "(1231950, 14)\n",
      "(307986, 14)\n",
      "       ∆t  pkt_len  ip_len  tcp_hea_len  tcp_flag_ack  tcp_flag_cwr  \\\n",
      "0  0.0000       66    52.0         32.0           0.0           0.0   \n",
      "1  0.0327       66    52.0         32.0           1.0           0.0   \n",
      "2  0.0002       54    40.0         20.0           1.0           0.0   \n",
      "3  0.0017      396   382.0         20.0           1.0           0.0   \n",
      "4  0.0363      551   537.0         20.0           1.0           0.0   \n",
      "\n",
      "   tcp_flag_ecn  tcp_flag_urg  tcp_flag_psh  tcp_flag_rst  tcp_flag_syn  \\\n",
      "0           0.0           0.0           0.0           0.0           1.0   \n",
      "1           0.0           0.0           0.0           0.0           1.0   \n",
      "2           0.0           0.0           0.0           0.0           0.0   \n",
      "3           0.0           0.0           1.0           0.0           0.0   \n",
      "4           0.0           0.0           1.0           0.0           0.0   \n",
      "\n",
      "   tcp_flag_fin  tcp_win_si2  stalling_event  \n",
      "0           0.0       8192.0               0  \n",
      "1           0.0      65000.0               0  \n",
      "2           0.0        256.0               0  \n",
      "3           0.0        256.0               0  \n",
      "4           0.0      64658.0               0  \n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# load the new file\n",
    "#dataset = read_csv('household_power_consumption_days.csv', header=0, infer_datetime_format=True, parse_dates=['datetime'], index_col=['datetime'])\n",
    "# split into train and test\n",
    "train, test = split_dataset(df)\n",
    "# evaluate model and get scores\n",
    "n_input = 200\n",
    "#score, scores = evaluate_model(train, test, n_input)\n",
    "# summarize scores\n",
    "#summarize_scores('lstm', score, scores)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#print(train.head())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "(17247300, 1)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "data = np.array(train)\n",
    "data = data.reshape((data.shape[0]*data.shape[1],1))\n",
    "print(data.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_x, train_y = to_supervised(train, n_input=200)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_x, train_y = to_supervised(train, 200, n_out=100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(train_x.shape) #200 de input, 100 output\n",
    "print(train_y.shape)\n",
    "\n",
    "print(type(train_x))\n",
    "print(type(train_y))\n",
    "history=[x for x in train]\n",
    "print(type(history))\n",
    "data= np.array(history)\n",
    "data = data.reshape((data.shape[0]*data.shape[1], data.shape[2]))\n",
    "\t# retrieve last observations for input data\n",
    "input_x = data[-100000:, -3]\n",
    "print(input_x)\n",
    "#print(data.shape)\n",
    "#print(sum(data==0)\n",
    "input_x = input_x.reshape((1, len(input_x), 1))\n",
    "print(input_x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "verbose, epochs, batch_size = 0, 50, 100\n",
    "n_timesteps, n_features, n_outputs = train_x.shape[1], train_x.shape[2], train_y.shape[1]\n",
    "# reshape output into [samples, timesteps, features]\n",
    "train_y = train_y.reshape((train_y.shape[0], train_y.shape[1], 1)) #Features es 3?\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu',\n",
    "                               input_shape=(n_timesteps, n_features))))\n",
    "model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu',\n",
    "                               kernel_regularizer=l2(0.001), bias_regularizer=l2(0.001))))\n",
    "#model.add(TimeDistributed(Dropout(0.5)))\n",
    "model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(RepeatVector(n_outputs))\n",
    "model.add(CuDNNLSTM(32, kernel_regularizer=l2(0.0001), bias_regularizer=l2(0.0001),\n",
    "                  recurrent_regularizer=l2(0.0001), activity_regularizer=l2(0.0001),\n",
    "                 return_sequences = True))\n",
    "#model.add(CuDNNLSTM(50, kernel_regularizer=l2(0.001), bias_regularizer=l2(0.001),\n",
    "#                    recurrent_regularizer=l2(0.001), activity_regularizer=l2(0.001)))\n",
    "#model.add(Dropout(0.5)) #DESCOMENTADO respecto al email\n",
    "model.add(Dense(32, activation='relu',kernel_regularizer=l2(0.0001), bias_regularizer=l2(0.0001)))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
    "\n",
    "# fit network\n",
    "model.fit(train_x, train_y, epochs=20, batch_size=100, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "build_model(train, n_input)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}